
############################################
# pipeline for predicting stock price with news
# set true to run the pipeline, false to skip the pipeline
[pipeline]

ingestion_stock = true
ingestion_news = false
feature_factor = true
feature_news = false
strategy = false
evaluation = false




############################################
[info]
# local path to store all data (change to your local path)
# local_data_path = "/Users/xwpeng/Projects/Erdos_Finance_LLM_data"
local_data_path = "/Users/xiaokangwang/Documents/PycharmProjects/Projects for Erdos 2025 spring/dataset"

# This is the path on the Google Drive
# local_data_path = "/content/drive/MyDrive/Erdos_2025_spring/dataset"


# directories names for data files in the local "i.e., Google Drive" path
# data_raw: raw stock and news data
# data_clean: cleaned and processed stock and news data, which can be used for modeling directly
# model: all the models files
# feature: extracted features from the cleaned data
# stratergy: trading stratergies and action records
# evaluation: backtesting results
dirs_names = ["logs", "config_archive", "data_raw", "data_clean", "models", "feature", "stratergy", "evaluation"]

# Database settings
db_name = "stock_daily_data.db"
# news data for all stocks (listed in stock_symbol_list below)
db_news_name = "stock_news_data.db"




############################################
# parameters for each step in the pipeline
[ingestion]
# one more years to calculate the technical indicators
cherry_start_date = "2021-03-01"
# dates covered in the database
start_date = "2022-03-01"
end_date = "2025-02-28"
# for price and news ingestion
stock_list = ["AAPL", "COST", "CVX"]
# stock_list = "20250408_over_medium_selected.csv"

# news ingestion parameters
# Maximum number of news items to retrieve per ticker
# maximum allowed by the API is 1000
news_limit_per_api_call = 1000
# Maximum total number of API calls allowed
# maximum allowed by the Free API is 25 per day, unlimited for paid users
api_call_total_limit = 99999
# Maximum API calls allowed per minute (Alpha Vantage standard tier allows 5 calls per minute)
api_calls_per_minute_limit = 75
# overwrite the news table if it already exists
overwrite_news_table = true

[feature]
# Technical analysis factors configuration
# trend: MA, EMA, MACD, ADX
# momentum: RSI, ROC, MOM
# volatility: BBANDS, CCI, ATR
# volume: OBV, AD

[feature.factor_parameters]
# momentum
rsi_6 = { timeperiod = 6 }
rsi_12 = { timeperiod = 12 }
rsi_24 = { timeperiod = 24 }

roc_14 = { timeperiod = 14 } 
roc_30 = { timeperiod = 30 }
roc_60 = { timeperiod = 60 }

mom_14 = { timeperiod = 14 } 
mom_30 = { timeperiod = 30 }
mom_60 = { timeperiod = 60 }

# trend
ma_20 = { timeperiod = 20 }
ma_30 = { timeperiod = 30 }
ma_60 = { timeperiod = 60 }
ma_200 = { timeperiod = 200 }

ema_20 = { timeperiod = 20 }
ema_30 = { timeperiod = 30 }
ema_60 = { timeperiod = 60 }
ema_200 = { timeperiod = 200 } 

macd = { fastperiod = 12, slowperiod = 26, signalperiod = 9 } # return 3 columns: macd, macd_signal, macd_hist

adx = { timeperiod = 14 }

# volatility
bbands = { timeperiod = 20, nbdevup = 2, nbdevdn = 2 } # return 3 columns: upper, middle, lower

cci = { timeperiod = 14 }

atr = { timeperiod = 14 }

# volume
obv = {} 

ad = {}

[feature.llm_model]
# LLAMA_MODEL in the CONTRIBUTING.md
model_path = "~/Tools/llm_tools/models/gemma/gemma-3-4b-it-q4_0.gguf"
# LLAMA_LIB_OUTPUT in the CONTRIBUTING.md
lib_path = "~/Tools/llm_tools/lib/libllama.dylib"

[strategy]
# the agent we want to train
DDQN = false
PPO = true
A2C = true

# Whether use news as factors
news = false


# train date
train_start_date = "2022-03-01"
train_end_date = "2024-03-01"

# test date
eval_start_date = "2022-03-01"
eval_end_date = "2025-02-28"

# trading days
trading_days = 252

# trading ticker list
ticker = "AAPL"
tickers = ["AAPL", "COST", "CVX"]

# trading environment: Choose one environment
#environment = "single"
environment = "portfolio"

# trading cost bps
trading_cost_bps = 0
# time cost bps
time_cost_bps = 0

# Resolution of the actions
resolution = 11

# training parameters
# Hyperparameters for reinforcement learning
gamma = 0.99 # Disconting factor
tau = 100 # target network update frequency

# Neural Network Architecture
architecture = [256, 128, 64] # Units per layer
learning_rate = 0.001 # Learning learning_rate
l2_reg = 0.00001  # L2 regularization
dropout = 0.01

# Experience Replay
replay_capacity = 1000000
batch_size = 4096

# \epsilon greedy policy
epsilon_start = 1.0
epsilon_end = 0.01
epsilon_decay_steps = 250
epsilon_exponential_decay = 0.99

# max episode
max_episodes = 1000

# PPO parameters
PPO_learning_rate = 3e-3
PPO_time_steps = 1000

# A2C parameters
A2C_learning_rate = 3e-3
A2C_time_steps = 1000

[evaluation]




############################################
# automatically generate when run the predic_stock_w_news.py
# for virsion control of files
[date]